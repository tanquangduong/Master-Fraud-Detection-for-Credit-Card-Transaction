{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a3c18a7",
   "metadata": {},
   "source": [
    "# Load train and test dataset with pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f4630ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
      "0           0   2019-01-01 00:00:18  2703186189652095   \n",
      "1           1   2019-01-01 00:00:44      630423337322   \n",
      "2           2   2019-01-01 00:00:51    38859492057661   \n",
      "3           3   2019-01-01 00:01:16  3534093764340240   \n",
      "4           4   2019-01-01 00:03:06   375534208663984   \n",
      "\n",
      "                             merchant       category     amt      first  \\\n",
      "0          fraud_Rippin, Kub and Mann       misc_net    4.97   Jennifer   \n",
      "1     fraud_Heller, Gutmann and Zieme    grocery_pos  107.23  Stephanie   \n",
      "2                fraud_Lind-Buckridge  entertainment  220.11     Edward   \n",
      "3  fraud_Kutch, Hermiston and Farrell  gas_transport   45.00     Jeremy   \n",
      "4                 fraud_Keeling-Crist       misc_pos   41.96      Tyler   \n",
      "\n",
      "      last gender                        street  ...      lat      long  \\\n",
      "0    Banks      F                561 Perry Cove  ...  36.0788  -81.1781   \n",
      "1     Gill      F  43039 Riley Greens Suite 393  ...  48.8878 -118.2105   \n",
      "2  Sanchez      M      594 White Dale Suite 530  ...  42.1808 -112.2620   \n",
      "3    White      M   9443 Cynthia Court Apt. 038  ...  46.2306 -112.1138   \n",
      "4   Garcia      M              408 Bradley Rest  ...  38.4207  -79.4629   \n",
      "\n",
      "   city_pop                                job         dob  \\\n",
      "0      3495          Psychologist, counselling  1988-03-09   \n",
      "1       149  Special educational needs teacher  1978-06-21   \n",
      "2      4154        Nature conservation officer  1962-01-19   \n",
      "3      1939                    Patent attorney  1967-01-12   \n",
      "4        99     Dance movement psychotherapist  1986-03-28   \n",
      "\n",
      "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
      "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
      "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
      "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
      "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
      "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
      "\n",
      "   is_fraud  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
      "0           0   2020-06-21 12:14:25  2291163933867244   \n",
      "1           1   2020-06-21 12:14:33  3573030041201292   \n",
      "2           2   2020-06-21 12:14:53  3598215285024754   \n",
      "3           3   2020-06-21 12:15:15  3591919803438423   \n",
      "4           4   2020-06-21 12:15:17  3526826139003047   \n",
      "\n",
      "                               merchant        category    amt   first  \\\n",
      "0                 fraud_Kirlin and Sons   personal_care   2.86    Jeff   \n",
      "1                  fraud_Sporer-Keebler   personal_care  29.84  Joanne   \n",
      "2  fraud_Swaniawski, Nitzsche and Welch  health_fitness  41.28  Ashley   \n",
      "3                     fraud_Haley Group        misc_pos  60.05   Brian   \n",
      "4                 fraud_Johnston-Casper          travel   3.19  Nathan   \n",
      "\n",
      "       last gender                       street  ...      lat      long  \\\n",
      "0   Elliott      M            351 Darlene Green  ...  33.9659  -80.9355   \n",
      "1  Williams      F             3638 Marsh Union  ...  40.3207 -110.4360   \n",
      "2     Lopez      F         9333 Valentine Point  ...  40.6729  -73.5365   \n",
      "3  Williams      M  32941 Krystal Mill Apt. 552  ...  28.5697  -80.8191   \n",
      "4    Massey      M     5783 Evan Roads Apt. 465  ...  44.2529  -85.0170   \n",
      "\n",
      "   city_pop                     job         dob  \\\n",
      "0    333497     Mechanical engineer  1968-03-19   \n",
      "1       302  Sales professional, IT  1990-01-17   \n",
      "2     34496       Librarian, public  1970-10-21   \n",
      "3     54767            Set designer  1987-07-25   \n",
      "4      1126      Furniture designer  1955-07-06   \n",
      "\n",
      "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
      "0  2da90c7d74bd46a0caf3777415b3ebd3  1371816865  33.986391  -81.200714   \n",
      "1  324cc204407e99f51b0d6ca0055005e7  1371816873  39.450498 -109.960431   \n",
      "2  c81755dbbbea9d5c77f094348a7579be  1371816893  40.495810  -74.196111   \n",
      "3  2159175b9efe66dc301f149d3d5abf8c  1371816915  28.812398  -80.883061   \n",
      "4  57ff021bd3f328f8738bb535c302a31b  1371816917  44.959148  -85.884734   \n",
      "\n",
      "   is_fraud  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load required panda package\n",
    "import pandas as pd\n",
    "\n",
    "# Load train dataset\n",
    "train_path = './datasets/fraudTrain.csv'\n",
    "df_train = pd.read_csv(train_path)\n",
    "\n",
    "# Get a quick view on train dataset feature and value\n",
    "print(df_train.head())\n",
    "\n",
    "#Load test dataset\n",
    "test_path = './datasets/fraudTest.csv'\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "# Get a quick view on test dataset feature and value\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a30dcd2",
   "metadata": {},
   "source": [
    "# Show basic statistical summries of the train / test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "693532fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train dataframe: (1296675, 23)\n",
      "Shape of test dataframe: (555719, 23)\n",
      "------------------Train Dataframe info------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   Unnamed: 0             1296675 non-null  int64  \n",
      " 1   trans_date_trans_time  1296675 non-null  object \n",
      " 2   cc_num                 1296675 non-null  int64  \n",
      " 3   merchant               1296675 non-null  object \n",
      " 4   category               1296675 non-null  object \n",
      " 5   amt                    1296675 non-null  float64\n",
      " 6   first                  1296675 non-null  object \n",
      " 7   last                   1296675 non-null  object \n",
      " 8   gender                 1296675 non-null  object \n",
      " 9   street                 1296675 non-null  object \n",
      " 10  city                   1296675 non-null  object \n",
      " 11  state                  1296675 non-null  object \n",
      " 12  zip                    1296675 non-null  int64  \n",
      " 13  lat                    1296675 non-null  float64\n",
      " 14  long                   1296675 non-null  float64\n",
      " 15  city_pop               1296675 non-null  int64  \n",
      " 16  job                    1296675 non-null  object \n",
      " 17  dob                    1296675 non-null  object \n",
      " 18  trans_num              1296675 non-null  object \n",
      " 19  unix_time              1296675 non-null  int64  \n",
      " 20  merch_lat              1296675 non-null  float64\n",
      " 21  merch_long             1296675 non-null  float64\n",
      " 22  is_fraud               1296675 non-null  int64  \n",
      "dtypes: float64(5), int64(6), object(12)\n",
      "memory usage: 227.5+ MB\n",
      "None\n",
      "------------------Train Dataframe describe------------------\n",
      "         Unnamed: 0        cc_num           amt           zip           lat  \\\n",
      "count  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06   \n",
      "mean   6.483370e+05  4.171920e+17  7.035104e+01  4.880067e+04  3.853762e+01   \n",
      "std    3.743180e+05  1.308806e+18  1.603160e+02  2.689322e+04  5.075808e+00   \n",
      "min    0.000000e+00  6.041621e+10  1.000000e+00  1.257000e+03  2.002710e+01   \n",
      "25%    3.241685e+05  1.800429e+14  9.650000e+00  2.623700e+04  3.462050e+01   \n",
      "50%    6.483370e+05  3.521417e+15  4.752000e+01  4.817400e+04  3.935430e+01   \n",
      "75%    9.725055e+05  4.642255e+15  8.314000e+01  7.204200e+04  4.194040e+01   \n",
      "max    1.296674e+06  4.992346e+18  2.894890e+04  9.978300e+04  6.669330e+01   \n",
      "\n",
      "               long      city_pop     unix_time     merch_lat    merch_long  \\\n",
      "count  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06   \n",
      "mean  -9.022634e+01  8.882444e+04  1.349244e+09  3.853734e+01 -9.022646e+01   \n",
      "std    1.375908e+01  3.019564e+05  1.284128e+07  5.109788e+00  1.377109e+01   \n",
      "min   -1.656723e+02  2.300000e+01  1.325376e+09  1.902779e+01 -1.666712e+02   \n",
      "25%   -9.679800e+01  7.430000e+02  1.338751e+09  3.473357e+01 -9.689728e+01   \n",
      "50%   -8.747690e+01  2.456000e+03  1.349250e+09  3.936568e+01 -8.743839e+01   \n",
      "75%   -8.015800e+01  2.032800e+04  1.359385e+09  4.195716e+01 -8.023680e+01   \n",
      "max   -6.795030e+01  2.906700e+06  1.371817e+09  6.751027e+01 -6.695090e+01   \n",
      "\n",
      "           is_fraud  \n",
      "count  1.296675e+06  \n",
      "mean   5.788652e-03  \n",
      "std    7.586269e-02  \n",
      "min    0.000000e+00  \n",
      "25%    0.000000e+00  \n",
      "50%    0.000000e+00  \n",
      "75%    0.000000e+00  \n",
      "max    1.000000e+00  \n"
     ]
    }
   ],
   "source": [
    "# Get dataframe shapes\n",
    "print('Shape of train dataframe:', df_train.shape)\n",
    "print('Shape of test dataframe:', df_test.shape)\n",
    "\n",
    "# Get train data info: count, feature names, data types, missing data counts\n",
    "print('------------------Train Dataframe info------------------')\n",
    "print(df_train.info())\n",
    "\n",
    "# Get statistical summaries for each feature\n",
    "print('------------------Train Dataframe describe------------------')\n",
    "print(df_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85a42fa",
   "metadata": {},
   "source": [
    "# Combine train and test dataframes and rename feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b3b7972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Shape of combined dataframe:\n",
      " (1852394, 23)\n",
      "\n",
      " Old feature names:\n",
      " ['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category', 'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time', 'merch_lat', 'merch_long', 'is_fraud']\n",
      "\n",
      " Dictionary of old-new feature names:\n",
      " {'Unnamed: 0': 'index', 'trans_date_trans_time': 'transaction_time', 'cc_num': 'account_number', 'merchant': 'merchant_name', 'category': 'category', 'amt': 'transaction_amount', 'first': 'first_name', 'last': 'last_name', 'gender': 'gender', 'street': 'street', 'city': 'city', 'state': 'state', 'zip': 'zip', 'lat': 'client_latitude', 'long': 'client_longitude', 'city_pop': 'city_population', 'job': 'job', 'dob': 'birthday', 'trans_num': 'transaction_number', 'unix_time': 'unix_time', 'merch_lat': 'merchant_latitude', 'merch_long': 'merchant_longitude', 'is_fraud': 'is_fraud'}\n",
      "\n",
      " Combine dataframe with new feature names:\n",
      "    index     transaction_time    account_number  \\\n",
      "0      0  2019-01-01 00:00:18  2703186189652095   \n",
      "1      1  2019-01-01 00:00:44      630423337322   \n",
      "\n",
      "                     merchant_name     category  transaction_amount  \\\n",
      "0       fraud_Rippin, Kub and Mann     misc_net                4.97   \n",
      "1  fraud_Heller, Gutmann and Zieme  grocery_pos              107.23   \n",
      "\n",
      "  first_name last_name gender                        street  ...  \\\n",
      "0   Jennifer     Banks      F                561 Perry Cove  ...   \n",
      "1  Stephanie      Gill      F  43039 Riley Greens Suite 393  ...   \n",
      "\n",
      "  client_latitude client_longitude  city_population  \\\n",
      "0         36.0788         -81.1781             3495   \n",
      "1         48.8878        -118.2105              149   \n",
      "\n",
      "                                 job    birthday  \\\n",
      "0          Psychologist, counselling  1988-03-09   \n",
      "1  Special educational needs teacher  1978-06-21   \n",
      "\n",
      "                 transaction_number   unix_time merchant_latitude  \\\n",
      "0  0b242abb623afc578575680df30655b9  1325376018         36.011293   \n",
      "1  1f76529f8574734946361c461b024d99  1325376044         49.159047   \n",
      "\n",
      "  merchant_longitude  is_fraud  \n",
      "0         -82.048315         0  \n",
      "1        -118.186462         0  \n",
      "\n",
      "[2 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the two datasets to perform the same data preprocessing\n",
    "df_combined = pd.concat([df_train, df_test], axis=0)\n",
    "print('\\n Shape of combined dataframe:\\n', df_combined.shape)\n",
    "\n",
    "# Get a list of old feature names\n",
    "old_feature_names = list(df_train.columns)\n",
    "print('\\n Old feature names:\\n', old_feature_names)\n",
    "\n",
    "# Create a new corresponding feature names\n",
    "new_feature_names = ['index', 'transaction_time', 'account_number', 'merchant_name', 'category',\n",
    "       'transaction_amount', 'first_name', 'last_name', 'gender', 'street', 'city', 'state', 'zip',\n",
    "       'client_latitude', 'client_longitude', 'city_population', 'job', 'birthday', 'transaction_number', 'unix_time',\n",
    "       'merchant_latitude', 'merchant_longitude', 'is_fraud']\n",
    "\n",
    "# Create a dictionary to map the old feature names to the new ones\n",
    "feature_name_dict = {old_feature_names[i]: new_feature_names[i] for i in range(len(old_feature_names))}\n",
    "print('\\n Dictionary of old-new feature names:\\n', feature_name_dict)\n",
    "\n",
    "# Edit col/feature name\n",
    "df_combined = df_combined.rename(columns=feature_name_dict)\n",
    "print('\\n Combine dataframe with new feature names:\\n', df_combined.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495edf3d",
   "metadata": {},
   "source": [
    "# Analyze class labels with is_fraud feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c45f6dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Unique values:\n",
      " [0 1]\n",
      "\n",
      " Count unique values:\n",
      " 0    1289169\n",
      "1       7506\n",
      "Name: is_fraud, dtype: int64\n",
      "\n",
      " Percetage of unique values:\n",
      " 0    0.994211\n",
      "1    0.005789\n",
      "Name: is_fraud, dtype: float64\n",
      "\n",
      " Dataframe for fraud labels:\n",
      "    Class    Count  Percentage\n",
      "0      0  1289169    0.994211\n",
      "1      1     7506    0.005789\n"
     ]
    }
   ],
   "source": [
    "# Check uniaue values of is_fraud column\n",
    "print('\\n Unique values:\\n', df_train.is_fraud.unique())\n",
    "\n",
    "# Cound unique values of is_fraud column\n",
    "print('\\n Count unique values:\\n', df_train.is_fraud.value_counts())\n",
    "\n",
    "# Calculate percentage of unique values of is_fraud column\n",
    "print('\\n Percetage of unique values:\\n', df_train.is_fraud.value_counts(normalize=True))\n",
    "\n",
    "# Create dataframe for statistics of fraud labels\n",
    "df_fraud_stat = pd.DataFrame({'Class': df_train.is_fraud.unique(),\n",
    "                             'Count': df_train.is_fraud.value_counts(),\n",
    "                             'Percentage': df_train.is_fraud.value_counts(normalize=True)})\n",
    "print('\\n Dataframe for fraud labels:\\n', df_fraud_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eef0f2",
   "metadata": {},
   "source": [
    "# Feature engineering techniques on the credit card transaction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55669de5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Convert transaction_time from string to datetime type. Add transaction date, hour, month to combined dataframe\n",
    "df_combined.transaction_time = pd.to_datetime(df_combined.transaction_time)\n",
    "df_combined['transaction_date'] = df_combined.transaction_time.dt.strftime('%Y-%m-%d')\n",
    "df_combined['transaction_hour'] = df_combined.transaction_time.dt.strftime('%H')\n",
    "df_combined['transaction_month'] = df_combined.transaction_time.dt.strftime('%m')\n",
    "\n",
    "# Convert transaction_birthday from string to datetime type. Add 'birthday_date' and 'age' features to combined dataframe\n",
    "df_combined.birthday = pd.to_datetime(df_combined.birthday)\n",
    "df_combined['birthday_date'] = df_combined.birthday.dt.strftime('%Y-%m-%d')\n",
    "df_combined['age'] = (df_combined.transaction_time - df_combined.birthday).astype('timedelta64[Y]')\n",
    "\n",
    "# calculate transaction distance \n",
    "distance_trans_longitude = df_combined.merchant_longitude - df_combined.client_longitude\n",
    "distance_trans_lattitude = df_combined.merchant_latitude - df_combined.client_latitude\n",
    "distance_trans = np.sqrt(distance_trans_longitude**2 + distance_trans_lattitude**2)\n",
    "\n",
    "# Add distance features to combined dataframe\n",
    "df_combined['transaction_longitude_distance'] = distance_trans_longitude\n",
    "df_combined['transaction_lattitude_distance'] = distance_trans_lattitude\n",
    "df_combined['transaction_distance'] = distance_trans\n",
    "\n",
    "# Create age_interval function\n",
    "def age_interval(x):\n",
    "    \"\"\"\n",
    "    Binning age values to categorical ones with 5 categories:\n",
    "    'Less than 20', 'Between 20 and 30', 'Between 30 and 40', \n",
    "    'Between 40 and 50', 'Between 50 and 60' and 'Larger than 60'\n",
    "    \"\"\"\n",
    "    if x < 20:\n",
    "        return \"Less than 20\" \n",
    "    elif x >=20 and x < 30:\n",
    "        return \"Between 20 and 30\"\n",
    "    elif x >=30 and x < 40:\n",
    "        return \"Between 30 and 40\"\n",
    "    elif x >=40 and x < 50:\n",
    "        return \"Between 40 and 50\"\n",
    "    elif x >=50 and x < 60:\n",
    "        return \"Between 50 and 60\"\n",
    "    else: \n",
    "        return \"Larger than 60\"\n",
    "\n",
    "# Create rename function for gender feature\n",
    "def gender_rename(x):\n",
    "    \"\"\"\n",
    "        Rename gender value: 'M' to 'Male' \n",
    "        and 'F' to 'Female'\n",
    "    \"\"\"\n",
    "    if x == 'M':\n",
    "        return \"Male\" \n",
    "    else: \n",
    "        return \"Female\"\n",
    "    \n",
    "# Create 'age_intervals' \n",
    "df_combined['age_intervals'] = df_combined.age.map(lambda x : age_interval(x))\n",
    "\n",
    "# Rename gender values\n",
    "df_combined['gender'] = df_combined.gender.map(lambda x : gender_rename(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ffea8c",
   "metadata": {},
   "source": [
    "# Get and save preprocessed train and test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ce4748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lenth of train dataset\n",
    "train_samples_len = df_train.shape[0]\n",
    "\n",
    "# Get preprocessed train and test dataframes\n",
    "df_train_preprocessed = df_combined.iloc[:train_samples_len, :]\n",
    "df_test_preprocessed = df_combined.iloc[train_samples_len:,:]\n",
    "\n",
    "# Save the preprocessed dataframes into new corresponding csv files for further analyze later\n",
    "df_train_preprocessed.to_csv('./datasets/df_train_preprocessed.csv')\n",
    "df_test_preprocessed.to_csv('./datasets/df_test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9023c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
